{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# TEAM MEMBERS:\n",
    "# MUHAMMAD MUHAIMIN MAZNI 1917953\n",
    "# HASSAN AHMED RAMADAN ALI 1916883\n",
    "# MUHAMMAD YUSOFF JAMALUDDIN 2016799\n",
    "# PUTRA AHMAD MAARIFUDDIN AHMAD MIZANUDIN 2012657\n",
    "\n",
    "# 1. Fill the '.envTemplate' with your credential and rename it to '.env' only,\n",
    "# the load_dotenv() module will read the content base on the name you gave in the file, case sensitive.\n",
    "\n",
    "# 2. Importing necessary packages, make sure to pip install <packageName> first\n",
    "import os\n",
    "from dotenv import load_dotenv\n",
    "\n",
    "# 3. Loading API Credentials\n",
    "load_dotenv()\n",
    "api_id = os.getenv(\"API_ID\")\n",
    "api_hash = os.getenv(\"API_HASH\")\n",
    "username = os.getenv(\"USERNAME\")\n",
    "\n",
    "# Example Channel to scrape, IF fails you have to JOIN the channel.\n",
    "watsons = os.getenv(\"WATSONS\")  # Watsons\n",
    "devhub = os.getenv(\"DEVHUB\")  # DevHub\n",
    "# Channel for Assignments\n",
    "cplaction = \"https://t.me/cplaction\"  # Will close\n",
    "childrenshd = \"https://t.me/childrenshd\"  # CA Michigan Group\n",
    "pediatrics1s = \"https://t.me/Pediatrics1s\"  # Not Malaysia\n",
    "SaveOurChildren2023 = \"https://t.me/SAVEOURCHILDREN2023\"  # Trafficking News\n",
    "stopCA = \"https://t.me/stopCA\"  # Child Abuse Channel report counter"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "from telethon.sync import TelegramClient\n",
    "\n",
    "# ----------------------- CHANNEL TO SCRAPE, WORD TO SEARCH AND DATA STORAGE -----------------------\n",
    "channelName = SaveOurChildren2023  # Channel to scrape, you can use the channel link or username starts with @\n",
    "searchWord = \"#childabuse, child abuse\"  # Word to search in str format\n",
    "CSVOutputFileName = (\n",
    "    \"childAbuseSearchOutput.csv\"  # Make sure to add '.csv' as file extension\n",
    ")\n",
    "JSONOutputFileName = (\n",
    "    \"childAbuseSearchOutput.json\"  # Make sure to add '.json' as file extension\n",
    ")\n",
    "data = []  # stores all our data in the format SENDER_ID, MSG\n",
    "\n",
    "\n",
    "# ------------------- MAIN FUNCTION ----------------------------\n",
    "async with TelegramClient(username, api_id, api_hash) as client:\n",
    "    async for message in client.iter_messages(\n",
    "        channelName, search=searchWord, limit=100\n",
    "    ):\n",
    "        data.append(\n",
    "            [message.sender_id, message.text]\n",
    "        )  # In this example we are taking the sender_id and their message.\n",
    "\n",
    "\n",
    "# ------------------ OUTPUT FILE YOU WANT TO USE -------------------------\n",
    "## Create CSV file as output\n",
    "df = pd.DataFrame(data, columns=[\"SENDER\", \"MESSAGE\"])  # Creates a new dataframe\n",
    "df.to_csv(CSVOutputFileName, encoding=\"utf-8\")  # Save to a CSV file\n",
    "\n",
    "## Create JSON file as output\n",
    "df.to_json(JSONOutputFileName)  # Convert DataFrame to JSON.\n",
    "# You can use your IDE formatter to 'arrange' the content of the JSON file"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from textblob import TextBlob\n",
    "\n",
    "# Store the texts into an array and calculate the number of each sentiment\n",
    "positive = 0\n",
    "negative = 0\n",
    "negation = 0\n",
    "booster_inc = 0\n",
    "booster_decr = 0\n",
    "\n",
    "# Array of the files\n",
    "data = []\n",
    "positive = []\n",
    "negative = []\n",
    "negation = []\n",
    "booster_inc = []\n",
    "booster_decr = []\n",
    "\n",
    "# Open the file in read mode (DATA)\n",
    "with open('positive.txt', 'r') as file:\n",
    "    # Read the contents of the file\n",
    "    file_contents = file.read()\n",
    "    \n",
    "    # Split the contents into lines\n",
    "    lines = file_contents.splitlines()\n",
    "\n",
    "# Open the file in read mode (POSITIVE)\n",
    "with open('positive.txt', 'r') as file:\n",
    "    # Read the contents of the file\n",
    "    file_contents = file.read()\n",
    "    \n",
    "    # Split the contents into lines\n",
    "    lines = file_contents.splitlines()\n",
    "\n",
    "# Open the file in read mode (NEGATIVE)\n",
    "with open('negative.txt', 'r') as file:\n",
    "    # Read the contents of the file\n",
    "    file_contents = file.read()\n",
    "    \n",
    "    # Split the contents into lines\n",
    "    lines = file_contents.splitlines()\n",
    "\n",
    "# Open the file in read mode (NEGATION)\n",
    "with open('negation.txt', 'r') as file:\n",
    "    # Read the contents of the file\n",
    "    file_contents = file.read()\n",
    "    \n",
    "    # Split the contents into lines\n",
    "    lines = file_contents.splitlines()\n",
    "\n",
    "# Open the file in read mode (BOOSTER_INC)\n",
    "with open('booster_inc.txt', 'r') as file:\n",
    "    # Read the contents of the file\n",
    "    file_contents = file.read()\n",
    "    \n",
    "    # Split the contents into lines\n",
    "    lines = file_contents.splitlines()\n",
    "\n",
    "# Open the file in read mode (BOOSTER_DECR)\n",
    "with open('booster_decr.txt', 'r') as file:\n",
    "    # Read the contents of the file\n",
    "    file_contents = file.read()\n",
    "    \n",
    "    # Split the contents into lines\n",
    "    lines = file_contents.splitlines()\n",
    "\n",
    "# # Print the lines (To Check the Array Content)\n",
    "for positive in lines:\n",
    "    print(positive)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Read the array and \n",
    "\n",
    "for tweets in tweets:\n",
    "    print(tweets.text)\n",
    "    tweet_list.append(tweets.text)\n",
    "    analysis = TextBlob(tweets.text)\n",
    "    score = SentimentIntensityAnalyzer().polarity_scores(tweets.text)\n",
    "    neg = score['neg']\n",
    "    neu = score['neu']\n",
    "    pos = score['pos']\n",
    "    comp = score['compound']\n",
    "    polarity += analysis.sentiment.polarity\n",
    "\n",
    "    if neg > pos:\n",
    "        negative_list.append(tweets.text)\n",
    "        negative += 1\n",
    "      \n",
    "\n",
    "    elif pos > neg:\n",
    "        positive_list.append(tweets.text)\n",
    "        positive += 1\n",
    "\n",
    "    elif pos == neg:\n",
    "        neutral_list.append(tweets.text)\n",
    "        neutral += 1\n",
    "\n",
    "positive_score = percentage(positive, noOfTweet)\n",
    "neutral_score = percentage(neutral, noOfTweet)\n",
    "negative_score = percentage(negative, noOfTweet)\n",
    "\n",
    "print(\"Positive tweets percentage: \", positive_score)\n",
    "print(\"Neutral tweets percentage: \", neutral_score)\n",
    "print(\"Negative tweets percentage: \", negative_score)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.11"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
